{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3af9bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from einops import rearrange\n",
    "from skimage import measure\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import warnings\n",
    "import json\n",
    "import torch\n",
    "warnings.filterwarnings('ignore')\n",
    "global ImgSize\n",
    "\n",
    "import time\n",
    "\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ee9ce85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch evaluated A = 50, B = 100, C = 250\n"
     ]
    }
   ],
   "source": [
    "############################################################################\n",
    "#  CONFIG\n",
    "############################################################################\n",
    "\n",
    "Anomaly = os.listdir(os.path.join('/home/nicerons/Documents', 'test2'))\n",
    "RootDir = '/home/nicerons/Documents'\n",
    "ExpFolder = '/home/nicerons/Documents/KI67_Normal_Tumor_test2'\n",
    "Steps = [50,100,250]\n",
    "print(f'Epoch evaluated A = {Steps[0]}, B = {Steps[1]}, C = {Steps[2]}')\n",
    "TestImgDir = os.path.join(RootDir, 'test2')\n",
    "ImgSize = 128\n",
    "FMOnly = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2dd15854",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FMOnly:\n",
    "    ScoresTrainIM_A = os.path.join(RootDir,ExpFolder,f'ScoresIM_{Steps[0]}_Train')\n",
    "    ScoresTrainIM_B = os.path.join(RootDir,ExpFolder,f'ScoresIM_{Steps[1]}_Train')\n",
    "    ScoresTrainIM_C = os.path.join(RootDir,ExpFolder,f'ScoresIM_{Steps[2]}_Train')\n",
    "\n",
    "    ScoresTestIM_A = os.path.join(RootDir,ExpFolder,f'ScoresIM_{Steps[0]}')\n",
    "    ScoresTestIM_B = os.path.join(RootDir,ExpFolder,f'ScoresIM_{Steps[1]}')\n",
    "    ScoresTestIM_C = os.path.join(RootDir,ExpFolder,f'ScoresIM_{Steps[2]}')\n",
    "\n",
    "ScoresTrainFM_A = os.path.join(RootDir,ExpFolder,f'ScoresFM_{Steps[0]}_Train')\n",
    "ScoresTrainFM_B = os.path.join(RootDir,ExpFolder,f'ScoresFM_{Steps[1]}_Train')\n",
    "ScoresTrainFM_C = os.path.join(RootDir,ExpFolder,f'ScoresFM_{Steps[2]}_Train')\n",
    "\n",
    "ScoresTestFM_A = os.path.join(RootDir,ExpFolder,f'ScoresFM_{Steps[0]}')\n",
    "ScoresTestFM_B = os.path.join(RootDir,ExpFolder,f'ScoresFM_{Steps[1]}')\n",
    "ScoresTestFM_C = os.path.join(RootDir,ExpFolder,f'ScoresFM_{Steps[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ac27897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FMOnly:\n",
    "    ReconsTrainIM_A = os.path.join(RootDir,ExpFolder,f'ReconsIM_{Steps[0]}_Train')\n",
    "    ReconsTrainIM_B = os.path.join(RootDir,ExpFolder,f'ReconsIM_{Steps[1]}_Train')\n",
    "    ReconsTrainIM_C = os.path.join(RootDir,ExpFolder,f'ReconsIM_{Steps[2]}_Train')\n",
    "\n",
    "    ReconsTestIM_A = os.path.join(RootDir,ExpFolder,f'ReconsIM_{Steps[0]}')\n",
    "    ReconsTestIM_B = os.path.join(RootDir,ExpFolder,f'ReconsIM_{Steps[1]}')\n",
    "    ReconsTestIM_C = os.path.join(RootDir,ExpFolder,f'ReconsIM_{Steps[2]}')\n",
    "\n",
    "\n",
    "ReconsTrainFM_A = os.path.join(RootDir,ExpFolder,f'ReconsFM_{Steps[0]}_Train')\n",
    "ReconsTrainFM_B = os.path.join(RootDir,ExpFolder,f'ReconsFM_{Steps[1]}_Train')\n",
    "ReconsTrainFM_C = os.path.join(RootDir,ExpFolder,f'ReconsFM_{Steps[2]}_Train')\n",
    "\n",
    "ReconsTestFM_A = os.path.join(RootDir,ExpFolder,f'ReconsFM_{Steps[0]}')\n",
    "ReconsTestFM_B = os.path.join(RootDir,ExpFolder,f'ReconsFM_{Steps[1]}')\n",
    "ReconsTestFM_C = os.path.join(RootDir,ExpFolder,f'ReconsFM_{Steps[2]}')\n",
    "\n",
    "loss_path_file = os.path.join(RootDir,ExpFolder,'Loss.csv')\n",
    "loss_path_file_A  = os.path.join(RootDir,ExpFolder,f'Loss_{Steps[0]}.csv')\n",
    "loss_path_file_B  = os.path.join(RootDir,ExpFolder,f'Loss_{Steps[1]}.csv')\n",
    "loss_path_file_C  = os.path.join(RootDir,ExpFolder,f'Loss_{Steps[2]}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a0d7d",
   "metadata": {},
   "source": [
    "# Many function useful for the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d57873ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fm_and_im(root_dir,class_anomaly,Tumor = False):\n",
    "    Reconstructions = []\n",
    "    Labels = []\n",
    "    Names = []\n",
    "    if not Tumor:\n",
    "        for c in class_anomaly:\n",
    "            imglist = os.listdir(os.path.join(root_dir,c))\n",
    "            imglist\n",
    "            imglist.sort()\n",
    "            for i in imglist:\n",
    "                Labels.append(c)\n",
    "                Names.append(os.path.join(root_dir,c, i))\n",
    "                im =  np.load(os.path.join(root_dir,c, i))\n",
    "                im = np.squeeze(im)\n",
    "                Reconstructions.append(np.mean(im, axis = -1))\n",
    "    else:\n",
    "        imglist = os.listdir(os.path.join(root_dir,'Tumor'))\n",
    "        imglist\n",
    "        imglist.sort()\n",
    "        for i in imglist:\n",
    "            Labels.append('Tumor')\n",
    "            Names.append(os.path.join(root_dir, 'Tumor', i))\n",
    "            im =  np.load(os.path.join(root_dir, 'Tumor',  i))\n",
    "            im = np.squeeze(im)        \n",
    "            Reconstructions.append(np.mean(im, axis = -1))\n",
    "    Reconstructions = np.array(Reconstructions)\n",
    "    return Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "041578d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(root_dir = TestImgDir, class_anomaly = Anomaly):\n",
    "    Images = []\n",
    "    Labels = []\n",
    "    Names =  []\n",
    "    for c in class_anomaly:\n",
    "        imglist = os.listdir(os.path.join(root_dir,c))\n",
    "        imglist.sort()\n",
    "        for i in imglist:\n",
    "            Names.append(os.path.join(root_dir,c, i))\n",
    "            Labels.append(c)\n",
    "            im = cv2.imread(os.path.join(root_dir,c, i))\n",
    "            im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "            im = cv2.resize(im, (384,384))\n",
    "            Images.append(im)\n",
    "    Images = np.array(Images)\n",
    "    return Images, Labels, Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a9ab70b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scored_pictures(root_dir , class_anomaly = Anomaly, Tumor =False, resized=False):\n",
    "    Reconstructions = []\n",
    "    Labels = []\n",
    "    Names = []\n",
    "    if not Tumor:\n",
    "        for c in class_anomaly:\n",
    "            imglist = os.listdir(os.path.join(root_dir,c))\n",
    "            imglist.sort()\n",
    "            for i in imglist:\n",
    "                Labels.append(c)\n",
    "                Names.append(os.path.join(root_dir,c, i))\n",
    "                im =  np.load(os.path.join(root_dir,c, i))\n",
    "                im = np.squeeze(im)\n",
    "                if resized != False:\n",
    "                    im =cv2.resize(im,(ImgSize,ImgSize), interpolation=cv2.INTER_LINEAR)\n",
    "                Reconstructions.append(im)\n",
    "    else:\n",
    "        imglist = os.listdir(os.path.join(root_dir,'Tumor'))\n",
    "        imglist\n",
    "        imglist.sort()\n",
    "        for i in imglist:\n",
    "            Labels.append('Tumor')\n",
    "            Names.append(os.path.join(root_dir, 'Tumor', i))\n",
    "            im =  np.load(os.path.join(root_dir, 'Tumor',  i))\n",
    "            im = np.squeeze(im)\n",
    "            if resized != False:\n",
    "                im = cv2.resize(im,(ImgSize,ImgSize), interpolation=cv2.INTER_LINEAR)\n",
    "            Reconstructions.append(im)\n",
    "    Reconstructions = np.array(Reconstructions)\n",
    "    return Reconstructions, Labels, Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f6abd0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img):\n",
    "    img_r = []\n",
    "    for i in range(img.shape[0]):\n",
    "        img_r.append(cv2.resize(img[i], dsize=(ImgSize, ImgSize)))\n",
    "    img_r = np.array(img_r)\n",
    "    return img_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "db787021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gauss_filter(img, fsize=5):\n",
    "    filteredimg = []\n",
    "    for i in range(img.shape[0]):\n",
    "        test = img[i,:,:]\n",
    "        filteredimg.append(cv2.GaussianBlur(test,(fsize,fsize),0))\n",
    "    filteredimg = np.array(filteredimg)\n",
    "    filteredimg.shape\n",
    "    return filteredimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ed9d2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average_good_scores_map(NamesRecons, Scores, size=(512,512), ScoresGood = None):\n",
    "    if not ScoresGood is None:\n",
    "        good_tensor_mean = np.mean(ScoresGood, axis = 0)\n",
    "    else:\n",
    "        good_c = 0\n",
    "        for e in NamesRecons:\n",
    "            cat = e.split('/')[-2]\n",
    "            if cat == 'Tumor':\\\n",
    "                good_c += 1\n",
    "\n",
    "        good_tensor = np.zeros((good_c, size[0], size[1]))\n",
    "        id_ = 0\n",
    "        concat = 0\n",
    "        for e in NamesRecons:\n",
    "            cat = e.split('/')[-2]\n",
    "            if cat == 'Tumor':\n",
    "                good_tensor[concat,:,:] = Scores[id_,:,:]\n",
    "                concat += 1\n",
    "            id_ += 1\n",
    "        good_tensor_mean = np.mean(good_tensor, axis = 0)\n",
    "    scores_minus_means = []\n",
    "    for s in Scores:\n",
    "        scores_minus_means.append(abs(s-good_tensor_mean))\n",
    "    scores_minus_means =  np.array(scores_minus_means)\n",
    "    return scores_minus_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2f0c3f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minus_min(Scores_Halo,ScoresGood_Halo, ScoresIM_Halo, ScoresGoodIM_Halo ):\n",
    "    scores_minus_means = Average_good_scores_map(NamesRecons, Scores_Halo, size=(ImgSize,ImgSize),   ScoresGood = ScoresGood_Halo)\n",
    "\n",
    "    scoresIM_minus_means = Average_good_scores_map(NamesRecons, ScoresIM_Halo, size=(ImgSize,ImgSize), ScoresGood = ScoresGoodIM_Halo)\n",
    "\n",
    "    return scores_minus_means, scoresIM_minus_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "729c2b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Binarization(mask, thres = 0., type = 0):\n",
    "    if type == 0:\n",
    "        mask = np.where(mask > thres, 1., 0.)\n",
    "    elif type ==1:\n",
    "        mask = np.where(mask > thres, mask, 0.)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c034c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_labels(Labels, Tumor=0):\n",
    "    BLabels = []\n",
    "    for l in Labels:\n",
    "        if l == 'Tumor':\n",
    "            BLabels.append(Tumor)\n",
    "        else:\n",
    "            \n",
    "            BLabels.append(1-Tumor)\n",
    "    BLabels = np.array(BLabels)\n",
    "    return BLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "90d12e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_prediction_image_level(LabelsT, BLabels, InvBLabels, Scores, process_name, ReturnDFs = False):\n",
    "    # Prediction according to the mean\n",
    "    predsM = np.mean(np.mean(Scores,axis=1),axis=1)\n",
    "    print(Scores.shape)\n",
    "    df_predMeans = pd.DataFrame(BLabels)\n",
    "    df_predMeans['preds'] = predsM\n",
    "    df_predMeans['Labels'] = LabelsT\n",
    "    try:\n",
    "        roc_auc_score_mean = round(roc_auc_score(df_predMeans.iloc[:,0], df_predMeans.iloc[:,1]), 4)\n",
    "    except:\n",
    "        # May fail if only one class\n",
    "        roc_auc_score_mean = -1\n",
    "\n",
    "    if roc_auc_score_mean < 0.5:\n",
    "        df_predMeans = pd.DataFrame(InvBLabels)\n",
    "        df_predMeans['preds'] = predsM\n",
    "        df_predMeans['Labels'] = LabelsT\n",
    "        try:\n",
    "            roc_auc_score_mean = round(roc_auc_score(df_predMeans.iloc[:,0], df_predMeans.iloc[:,1]), 4)\n",
    "        except:\n",
    "            # May fail if only one class\n",
    "            roc_auc_score_mean = -1\n",
    "\n",
    "    # Prediction according to the max\n",
    "    predsX = Scores.max(1).max(1)    # for detection\n",
    "    df_predMaX = pd.DataFrame(BLabels)\n",
    "    df_predMaX['preds'] = predsX\n",
    "    df_predMaX['Labels'] = LabelsT\n",
    "    try:\n",
    "        roc_auc_scores_max = round(roc_auc_score(df_predMaX.iloc[:,0], df_predMaX.iloc[:,1]), 4)\n",
    "    except:\n",
    "        # May fail if only one class\n",
    "        roc_auc_scores_max = -1\n",
    "    if roc_auc_scores_max < 0.5 :\n",
    "        df_predMaX = pd.DataFrame(InvBLabels)\n",
    "        df_predMeans['preds'] = predsX\n",
    "        df_predMeans['Labels'] = LabelsT\n",
    "        try:\n",
    "            roc_auc_score_mean = round(roc_auc_score(df_predMeans.iloc[:,0], df_predMeans.iloc[:,1]), 4)\n",
    "        except:\n",
    "            # May fail if only one class\n",
    "            roc_auc_score_mean = -1\n",
    "\n",
    "    if ReturnDFs:\n",
    "        return df_predMeans, df_predMaX, roc_auc_score_mean, roc_auc_scores_max, process_name\n",
    "    else: \n",
    "        return  roc_auc_score_mean, roc_auc_scores_max, process_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1f0bd431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_res_dict(dict_cls_res):\n",
    "    best_by_mean = ['NA',0]\n",
    "    best_by_max = ['NA',0]\n",
    "    cls_by_mean = {}\n",
    "    cls_by_max = {}\n",
    "    NewKeyList = []\n",
    "    for k in dict_cls_res.keys():\n",
    "        NewKeyList.append(k[:-2])\n",
    "        cls_by_mean[k] = dict_cls_res[k][0]\n",
    "        cls_by_max[k] = dict_cls_res[k][1]\n",
    "        if dict_cls_res[k][0] > best_by_mean[1]:\n",
    "            best_by_mean[0] = k\n",
    "            best_by_mean[1] = dict_cls_res[k][0]\n",
    "        if dict_cls_res[k][1] > best_by_max[1]:\n",
    "            best_by_max[0] = k\n",
    "            best_by_max[1] = dict_cls_res[k][1]\n",
    "    return best_by_mean, best_by_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "907aecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_loss_table(DfLoss):\n",
    "    anomaly = []\n",
    "    exp_label = [] \n",
    "    predict_label = []\n",
    "    for i in range(DfLoss.shape[0]):\n",
    "        anomaly.append(DfLoss.iloc[i,1].split('/')[-2])\n",
    "        if DfLoss.iloc[i,1].split('/')[-2] == 'Tumor':\n",
    "            exp_label.append(0)\n",
    "        else:\n",
    "            exp_label.append(1)\n",
    "        predict_label.append(np.argmax(np.array(DfLoss.iloc[i,3:5].values)))\n",
    "    DfLoss['anomaly'] = anomaly\n",
    "    DfLoss['exp_label'] = exp_label\n",
    "    DfLoss['predict_label'] = predict_label  \n",
    "    return DfLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb1f335",
   "metadata": {},
   "source": [
    "# Data uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0c684a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Images, Labels, NamesImg =  get_images()\n",
    "#Masks_Halo, Labels, NamesMask = get_masks(size=(ImgSize,ImgSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b9a0de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not FMOnly:\n",
    "    ScoresTrainIM_A, LabelsG, NamesRecons = get_scored_pictures(ScoresTrainIM_A,   Tumor = True, resized=True)\n",
    "    ScoresTrainIM_B, LabelsG, NamesRecons = get_scored_pictures(ScoresTrainIM_B,  Tumor = True, resized=True)\n",
    "    ScoresTrainIM_C, LabelsG, NamesRecons = get_scored_pictures(ScoresTrainIM_C,  Tumor = True, resized=True)\n",
    "    \n",
    "\n",
    "\n",
    "    ScoresTestIM_A, Labels, NamesRecons = get_scored_pictures(ScoresTestIM_A, resized=True)\n",
    "    ScoresTestIM_B, Labels, NamesRecons = get_scored_pictures(ScoresTestIM_B, resized=True)\n",
    "    ScoresTestIM_C, Labels, NamesRecons = get_scored_pictures(ScoresTestIM_C, resized=True)\n",
    "\n",
    "\n",
    "    ReconsTrainIM_A = load_fm_and_im(ReconsTrainIM_A, Anomaly,Tumor = True)\n",
    "    ReconsTrainIM_B = load_fm_and_im(ReconsTrainIM_B,  Anomaly,Tumor = True)\n",
    "    ReconsTrainIM_C = load_fm_and_im(ReconsTrainIM_C,Anomaly,Tumor = True)\n",
    "\n",
    "    ReconsTestIM_A = load_fm_and_im(ReconsTestIM_A, Anomaly,Tumor = False)\n",
    "    ReconsTestIM_B = load_fm_and_im(ReconsTestIM_B,  Anomaly,Tumor = False)\n",
    "    ReconsTestIM_C = load_fm_and_im(ReconsTestIM_C, Anomaly,Tumor = False)\n",
    "\n",
    "\n",
    "\n",
    "ScoresTrainFM_A, LabelsG, NamesRecons = get_scored_pictures(ScoresTrainFM_A,  Tumor = True)\n",
    "ScoresTrainFM_B, LabelsG, NamesRecons = get_scored_pictures(ScoresTrainFM_B,  Tumor = True)\n",
    "ScoresTrainFM_C, LabelsG, NamesRecons = get_scored_pictures(ScoresTrainFM_C,  Tumor = True)\n",
    "\n",
    "\n",
    "ScoresTestFM_A, LabelsG, NamesRecons = get_scored_pictures(ScoresTestFM_A)\n",
    "ScoresTestFM_B, LabelsG, NamesRecons = get_scored_pictures(ScoresTestFM_B)\n",
    "ScoresTestFM_C, LabelsG, NamesRecons = get_scored_pictures(ScoresTestFM_C)\n",
    "\n",
    "ReconsTrainFM_A = load_fm_and_im(ReconsTrainFM_A, Anomaly,Tumor = True)\n",
    "ReconsTrainFM_B = load_fm_and_im(ReconsTrainFM_B, Anomaly,Tumor = True)\n",
    "ReconsTrainFM_C = load_fm_and_im(ReconsTrainFM_C, Anomaly,Tumor = True)\n",
    "\n",
    "ReconsTestFM_A = load_fm_and_im(ReconsTestFM_A,  Anomaly,Tumor = False)\n",
    "ReconsTestFM_B = load_fm_and_im(ReconsTestFM_B,Anomaly,Tumor = False)\n",
    "ReconsTestFM_C = load_fm_and_im(ReconsTestFM_C, Anomaly,Tumor = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc8769a",
   "metadata": {},
   "source": [
    "# Data post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "87cfaeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 135 135\n"
     ]
    }
   ],
   "source": [
    "print(len(Images), len(Labels), len(NamesImg))\n",
    "\n",
    "if not FMOnly:\n",
    "    scoresIMFilter_A = apply_gauss_filter(ScoresTestIM_A)\n",
    "    scoresIMFilter_B = apply_gauss_filter(ScoresTestIM_B)\n",
    "    scoresIMFilter_C = apply_gauss_filter(ScoresTestIM_C)\n",
    "\n",
    "    scoresFMNorm_A, scoresIMNorm_A,  = get_minus_min( ScoresTestFM_A ,ScoresTrainFM_A, ScoresTestIM_A, ScoresTrainIM_A )\n",
    "    scoresFMNorm_B, scoresIMNorm_B,  = get_minus_min(ScoresTestFM_B ,ScoresTrainFM_B, ScoresTestIM_B, ScoresTrainIM_B )\n",
    "    scoresFMNorm_C, scoresIMNorm_C,  = get_minus_min(ScoresTestFM_C ,ScoresTrainFM_C, ScoresTestIM_C, ScoresTrainIM_C )\n",
    "\n",
    "else:\n",
    "    scoresFMNorm_A = Average_good_scores_map(NamesRecons, ScoresTestFM_A, size=(ImgSize,ImgSize), ScoresGood = ScoresTrainFM_A)\n",
    "    scoresFMNorm_B = Average_good_scores_map(NamesRecons, ScoresTestFM_B, size=(ImgSize,ImgSize), ScoresGood = ScoresTrainFM_B)\n",
    "    scoresFMNorm_C = Average_good_scores_map(NamesRecons, ScoresTestFM_B, size=(ImgSize,ImgSize), ScoresGood = ScoresTrainFM_C)\n",
    "\n",
    "scoresFMFilter_A = apply_gauss_filter(ScoresTestFM_A)\n",
    "scoresFMFilter_B = apply_gauss_filter(ScoresTestFM_B)\n",
    "scoresFMFilter_C = apply_gauss_filter(ScoresTestFM_C)\n",
    "\n",
    "if not FMOnly:\n",
    "    scoresIMNormFilter_A = apply_gauss_filter(scoresIMNorm_A,3)\n",
    "    scoresIMNormFilter_B = apply_gauss_filter(scoresIMNorm_B,3)\n",
    "    scoresIMNormFilter_C = apply_gauss_filter(scoresIMNorm_C,3)\n",
    "\n",
    "scoresFMNormFilter_A = apply_gauss_filter(scoresFMNorm_A,3)\n",
    "scoresFMNormFilter_B = apply_gauss_filter(scoresFMNorm_B,3)\n",
    "scoresFMNormFilter_C = apply_gauss_filter(scoresFMNorm_C,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5e78f8",
   "metadata": {},
   "source": [
    "# Anomaly Detection at Image level\n",
    "## According to matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f2d3670d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 135 135\n",
      "(135, 128, 128)\n",
      "(135, 128, 128)\n",
      "(135, 128, 128)\n",
      "(135, 128, 128)\n",
      "(135, 128, 128)\n",
      "(135, 128, 128)\n",
      "(135, 128, 128)\n",
      "(135, 128, 128)\n",
      "(135, 128, 128)\n",
      "(135, 64, 64)\n",
      "(135, 64, 64)\n",
      "(135, 64, 64)\n",
      "(135, 64, 64)\n",
      "(135, 64, 64)\n",
      "(135, 64, 64)\n",
      "(135, 64, 64)\n",
      "(135, 64, 64)\n",
      "(135, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "if not FMOnly:\n",
    "    L_postprocess_matrix = [scoresIMNormFilter_A, scoresIMNormFilter_B, scoresIMNormFilter_C,\n",
    "                            scoresIMFilter_A, scoresIMFilter_B, scoresIMFilter_C,\n",
    "                            scoresIMNorm_A, scoresIMNorm_B, scoresIMNorm_C,\n",
    "                            scoresFMNorm_A, scoresFMNorm_B, scoresFMNorm_C,\n",
    "                            scoresFMFilter_A, scoresFMFilter_B, scoresFMFilter_C,\n",
    "                            scoresFMNormFilter_A, scoresFMNormFilter_B, scoresFMNormFilter_C]\n",
    "\n",
    "\n",
    "    L_ProcessName = [       'scoresIMNormFilter_A', 'scoresIMNormFilter_B', 'scoresIMNormFilter_C',\n",
    "                            'scoresIMFilter_A', 'scoresIMFilter_B', 'scoresIMFilter_C',\n",
    "                            'scoresIMNorm_A', 'scoresIMNorm_B', 'scoresIMNorm_C',\n",
    "                            'scoresFMNorm_A', 'scoresFMNorm_B', 'scoresFMNorm_C',\n",
    "                            'scoresFMFilter_A', 'scoresFMFilter_B', 'scoresFMFilter_C',\n",
    "                            'scoresFMNormFilter_A', 'scoresFMNormFilter_B', 'scoresFMNormFilter_C']\n",
    "    \n",
    "    \n",
    "    \n",
    "else:\n",
    "    L_postprocess_matrix = [scoresFMNorm_A, scoresFMNorm_B, scoresFMNorm_C,\n",
    "                            scoresFMFilter_A, scoresFMFilter_B, scoresFMFilter_C,\n",
    "                            scoresFMNormFilter_A, scoresFMNormFilter_B, scoresFMNormFilter_C]\n",
    "\n",
    "\n",
    "    L_ProcessName = ['scoresFMNorm_A', 'scoresFMNorm_B', 'scoresFMNorm_C',\n",
    "                     'scoresFMFilter_A', 'scoresFMFilter_B', 'scoresFMFilter_C',\n",
    "                     'scoresFMNormFilter_A', 'scoresFMNormFilter_B', 'scoresFMNormFilter_C']\n",
    "\n",
    "    \n",
    "print(len(Labels), len(BLabels), len(InvBLabels))    \n",
    "BLabels = get_binary_labels(Labels) # If Good Blabel = 0, Else Blabel = 1\n",
    "InvBLabels = get_binary_labels(Labels, Tumor=1) # If Good Blabel = 1, Else Blabel = 0\n",
    "\n",
    "\n",
    "dict_cls_res = {}\n",
    "for i in range(len(L_postprocess_matrix)):\n",
    "    roc_auc_score_mean, roc_auc_scores_max, process_name =  cls_prediction_image_level(Labels, BLabels, InvBLabels, L_postprocess_matrix[i],  L_ProcessName[i])\n",
    "    process_name_mean = process_name.split('_')[0] + '_mean_' + process_name.split('_')[1] \n",
    "    dict_cls_res[process_name_mean] = roc_auc_score_mean \n",
    "    process_name_max = process_name.split('_')[0] + '_max_' + process_name.split('_')[1] \n",
    "    dict_cls_res[process_name_max] =  roc_auc_scores_max\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cde5f1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scoresIMNormFilter_mean_A': 0.9554,\n",
       " 'scoresIMNormFilter_max_A': 0.7569,\n",
       " 'scoresIMNormFilter_mean_B': 0.9496,\n",
       " 'scoresIMNormFilter_max_B': 0.75,\n",
       " 'scoresIMNormFilter_mean_C': 0.9336,\n",
       " 'scoresIMNormFilter_max_C': 0.7498,\n",
       " 'scoresIMFilter_mean_A': 0.9207,\n",
       " 'scoresIMFilter_max_A': 0.738,\n",
       " 'scoresIMFilter_mean_B': 0.911,\n",
       " 'scoresIMFilter_max_B': 0.739,\n",
       " 'scoresIMFilter_mean_C': 0.8624,\n",
       " 'scoresIMFilter_max_C': 0.7379,\n",
       " 'scoresIMNorm_mean_A': 0.9559,\n",
       " 'scoresIMNorm_max_A': 0.7707,\n",
       " 'scoresIMNorm_mean_B': 0.9496,\n",
       " 'scoresIMNorm_max_B': 0.7701,\n",
       " 'scoresIMNorm_mean_C': 0.9342,\n",
       " 'scoresIMNorm_max_C': 0.7623,\n",
       " 'scoresFMNorm_mean_A': 0.9281,\n",
       " 'scoresFMNorm_max_A': 0.7889,\n",
       " 'scoresFMNorm_mean_B': 0.9276,\n",
       " 'scoresFMNorm_max_B': 0.7732,\n",
       " 'scoresFMNorm_mean_C': 0.9162,\n",
       " 'scoresFMNorm_max_C': 0.7633,\n",
       " 'scoresFMFilter_mean_A': 0.8827,\n",
       " 'scoresFMFilter_max_A': 0.7597,\n",
       " 'scoresFMFilter_mean_B': 0.8821,\n",
       " 'scoresFMFilter_max_B': 0.7545,\n",
       " 'scoresFMFilter_mean_C': 0.8752,\n",
       " 'scoresFMFilter_max_C': 0.7599,\n",
       " 'scoresFMNormFilter_mean_A': 0.9287,\n",
       " 'scoresFMNormFilter_max_A': 0.7787,\n",
       " 'scoresFMNormFilter_mean_B': 0.9275,\n",
       " 'scoresFMNormFilter_max_B': 0.7722,\n",
       " 'scoresFMNormFilter_mean_C': 0.916,\n",
       " 'scoresFMNormFilter_max_C': 0.7811}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_cls_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e79d822",
   "metadata": {},
   "source": [
    "## According to Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c75d6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_anomaly_detection_scores(DfLoss, FMOnly):\n",
    "    DfLoss = extend_loss_table(DfLoss)\n",
    "    \n",
    "    DfLoss['Inv_label'] = [-1] * DfLoss.shape[0]\n",
    "    DfLoss.loc[DfLoss['exp_label'] == 0,'Inv_label'] = 1\n",
    "    DfLoss.loc[DfLoss['exp_label'] == 1,'Inv_label'] = 0\n",
    "    \n",
    "    TotlossROC = round(roc_auc_score(DfLoss['exp_label'], DfLoss['loss']), 4)\n",
    "    if TotlossROC < 0.5:\n",
    "        TotlossROC = round(roc_auc_score(DfLoss['Inv_label'], DfLoss['loss']), 4)\n",
    "        \n",
    "    ClsLossScores = round(roc_auc_score(DfLoss['exp_label'], DfLoss['cls']), 4)\n",
    "    if ClsLossScores < 0.5:\n",
    "        ClsLossScores = round(roc_auc_score(DfLoss['Inv_label'], DfLoss['cls']), 4)\n",
    "        \n",
    "    MSEFMLossScores = round(roc_auc_score(DfLoss['exp_label'], DfLoss['MSEFM']), 4)\n",
    "    if MSEFMLossScores < 0.5:\n",
    "        MSEFMLossScores = round(roc_auc_score(DfLoss['Inv_label'], DfLoss['MSEFM']), 4)\n",
    "        \n",
    "    SSIMFMLossScores = round(roc_auc_score(DfLoss['exp_label'], DfLoss['SSIMFM']), 4)\n",
    "    if SSIMFMLossScores < 0.5:\n",
    "        SSIMFMLossScores = round(roc_auc_score(DfLoss['Inv_label'], DfLoss['SSIMFM']), 4)\n",
    "   \n",
    "    if not FMOnly:\n",
    "        MSEIMLossScores = round(roc_auc_score(DfLoss['exp_label'], DfLoss['MSEIM']), 4)\n",
    "        if MSEIMLossScores < 0.5:\n",
    "            MSEIMLossScores = round(roc_auc_score(DfLoss['Inv_label'], DfLoss['MSEIM']), 4)\n",
    "   \n",
    "        SSIMIMLossScores = round(roc_auc_score(DfLoss['exp_label'], DfLoss['SSIMIM']), 4)\n",
    "        if SSIMIMLossScores < 0.5:\n",
    "            SSIMIMLossScores = round(roc_auc_score(DfLoss['Inv_label'], DfLoss['SSIMIM']), 4)\n",
    "   \n",
    "    else:\n",
    "        MSEIMLossScores = 'NA'\n",
    "        SSIMIMLossScores = 'NA'\n",
    "    return TotlossROC, ClsLossScores, MSEFMLossScores, SSIMFMLossScores, MSEIMLossScores, SSIMIMLossScores\n",
    "\n",
    "try:\n",
    "    DfLoss = pd.read_csv(loss_path_file)\n",
    "    TotlossROC, ClsLossScores, MSEFMLossScores, SSIMFMLossScores, MSEIMLossScores, SSIMIMLossScores = get_loss_anomaly_detection_scores(DfLoss, FMOnly)\n",
    "    dict_cls_res['TotlossROC'] = TotlossROC\n",
    "    dict_cls_res['ClsLossScores'] = ClsLossScores\n",
    "    dict_cls_res['MSEFMLossScores'] = MSEFMLossScores\n",
    "    dict_cls_res['SSIMFMLossScores'] = SSIMFMLossScores\n",
    "    dict_cls_res['MSEIMLossScores'] = MSEIMLossScores\n",
    "    dict_cls_res['SSIMIMLossScores'] = SSIMIMLossScores\n",
    "    # print('Anomaly detction at image level dict (dict_cls_res ) : \\n ', dict_cls_res, '\\n\\n ')\n",
    " \n",
    "    \n",
    "except:\n",
    "    DfLoss_A = pd.read_csv(loss_path_file_A)\n",
    "    TotlossROC_A, ClsLossScores_A, MSEFMLossScores_A, SSIMFMLossScores_A, MSEIMLossScores_A, SSIMIMLossScores_A = get_loss_anomaly_detection_scores(DfLoss_A, FMOnly)\n",
    "    dict_cls_res['TotlossROC_A'] = TotlossROC_A\n",
    "    dict_cls_res['ClsLossScores_A'] = ClsLossScores_A\n",
    "    dict_cls_res['MSEFMLossScores_A'] = MSEFMLossScores_A\n",
    "    dict_cls_res['SSIMFMLossScores_A'] = SSIMFMLossScores_A\n",
    "    dict_cls_res['MSEIMLossScores_A'] = MSEIMLossScores_A\n",
    "    dict_cls_res['SSIMIMLossScores_A'] = SSIMIMLossScores_A\n",
    "        \n",
    "    DfLoss_B = pd.read_csv(loss_path_file_B)\n",
    "    TotlossROC_B, ClsLossScores_B, MSEFMLossScores_B, SSIMFMLossScores_B, MSEIMLossScores_B, SSIMIMLossScores_B = get_loss_anomaly_detection_scores(DfLoss_B, FMOnly)\n",
    "    dict_cls_res['TotlossROC_B'] = TotlossROC_B\n",
    "    dict_cls_res['ClsLossScores_B'] = ClsLossScores_B\n",
    "    dict_cls_res['MSEFMLossScores_B'] = MSEFMLossScores_B\n",
    "    dict_cls_res['SSIMFMLossScores_B'] = SSIMFMLossScores_B\n",
    "    dict_cls_res['MSEIMLossScores_B'] = MSEIMLossScores_B\n",
    "    dict_cls_res['SSIMIMLossScores_B'] = SSIMIMLossScores_B\n",
    "    \n",
    "    DfLoss_C = pd.read_csv(loss_path_file_C)\n",
    "    TotlossROC_C, ClsLossScores_C, MSEFMLossScores_C, SSIMFMLossScores_C, MSEIMLossScores_C, SSIMIMLossScores_C = get_loss_anomaly_detection_scores(DfLoss_C, FMOnly)\n",
    "    dict_cls_res['TotlossROC_C'] = TotlossROC_C\n",
    "    dict_cls_res['ClsLossScores_C'] = ClsLossScores_C\n",
    "    dict_cls_res['MSEFMLossScores_C'] = MSEFMLossScores_C\n",
    "    dict_cls_res['SSIMFMLossScores_C'] = SSIMFMLossScores_C\n",
    "    dict_cls_res['MSEIMLossScores_C'] = MSEIMLossScores_C\n",
    "    dict_cls_res['SSIMIMLossScores_C'] = SSIMIMLossScores_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f6bca62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scoresIMNormFilter_mean_A': 0.9554,\n",
       " 'scoresIMNormFilter_max_A': 0.7569,\n",
       " 'scoresIMNormFilter_mean_B': 0.9496,\n",
       " 'scoresIMNormFilter_max_B': 0.75,\n",
       " 'scoresIMNormFilter_mean_C': 0.9336,\n",
       " 'scoresIMNormFilter_max_C': 0.7498,\n",
       " 'scoresIMFilter_mean_A': 0.9207,\n",
       " 'scoresIMFilter_max_A': 0.738,\n",
       " 'scoresIMFilter_mean_B': 0.911,\n",
       " 'scoresIMFilter_max_B': 0.739,\n",
       " 'scoresIMFilter_mean_C': 0.8624,\n",
       " 'scoresIMFilter_max_C': 0.7379,\n",
       " 'scoresIMNorm_mean_A': 0.9559,\n",
       " 'scoresIMNorm_max_A': 0.7707,\n",
       " 'scoresIMNorm_mean_B': 0.9496,\n",
       " 'scoresIMNorm_max_B': 0.7701,\n",
       " 'scoresIMNorm_mean_C': 0.9342,\n",
       " 'scoresIMNorm_max_C': 0.7623,\n",
       " 'scoresFMNorm_mean_A': 0.9281,\n",
       " 'scoresFMNorm_max_A': 0.7889,\n",
       " 'scoresFMNorm_mean_B': 0.9276,\n",
       " 'scoresFMNorm_max_B': 0.7732,\n",
       " 'scoresFMNorm_mean_C': 0.9162,\n",
       " 'scoresFMNorm_max_C': 0.7633,\n",
       " 'scoresFMFilter_mean_A': 0.8827,\n",
       " 'scoresFMFilter_max_A': 0.7597,\n",
       " 'scoresFMFilter_mean_B': 0.8821,\n",
       " 'scoresFMFilter_max_B': 0.7545,\n",
       " 'scoresFMFilter_mean_C': 0.8752,\n",
       " 'scoresFMFilter_max_C': 0.7599,\n",
       " 'scoresFMNormFilter_mean_A': 0.9287,\n",
       " 'scoresFMNormFilter_max_A': 0.7787,\n",
       " 'scoresFMNormFilter_mean_B': 0.9275,\n",
       " 'scoresFMNormFilter_max_B': 0.7722,\n",
       " 'scoresFMNormFilter_mean_C': 0.916,\n",
       " 'scoresFMNormFilter_max_C': 0.7811,\n",
       " 'TotlossROC_A': 0.9276,\n",
       " 'ClsLossScores_A': 1.0,\n",
       " 'MSEFMLossScores_A': 0.8826,\n",
       " 'SSIMFMLossScores_A': 0.9563,\n",
       " 'MSEIMLossScores_A': 0.8826,\n",
       " 'SSIMIMLossScores_A': 0.9563,\n",
       " 'TotlossROC_B': 0.9241,\n",
       " 'ClsLossScores_B': 1.0,\n",
       " 'MSEFMLossScores_B': 0.8821,\n",
       " 'SSIMFMLossScores_B': 0.9521,\n",
       " 'MSEIMLossScores_B': 0.8821,\n",
       " 'SSIMIMLossScores_B': 0.9521,\n",
       " 'TotlossROC_C': 0.9131,\n",
       " 'ClsLossScores_C': 1.0,\n",
       " 'MSEFMLossScores_C': 0.8761,\n",
       " 'SSIMFMLossScores_C': 0.9366,\n",
       " 'MSEIMLossScores_C': 0.8761,\n",
       " 'SSIMIMLossScores_C': 0.9366}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_cls_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d68be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0291c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed30e5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
